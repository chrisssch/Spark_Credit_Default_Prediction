{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark practice - Credit Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The purpose of this notebook is to practice the basics of transforming data and machine learning in PySpark. I implement a simple pipeline for transforming the data and train and evaluate a logistic regression, decision tree, and random forest model.\n",
    "\n",
    "The data used is the [default of credit card clients data set](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients) \n",
    "by Yeh, I. C., & Lien, C. H. (2009) on payment defaults of Taiwenese customers, downloaded from the UCI Machine Learning Laboratory. This dataset has 30,000 observations for 23 features plus two columns with ID and the label for the default status.\n",
    "\n",
    "The label and the features are as follows:\n",
    "\n",
    "* DEFAULT: Default on payment (Yes = 1; No = 0)\n",
    "* LIMIT_BAL: Credit amount in New Taiwan dollar\n",
    "* SEX: Gender (1 = male; 2 = female). \n",
    "* EDUCATION: Education status (1 = graduate school; 2 = university; 3 = high school; 4 = others)\n",
    "* MARRIAGE: Marital status (1 = married; 2 = single; 3 = others)\n",
    "* AGE: Age in years\n",
    "* PAY_0 to PAY_6: Monthly payment records of the past 6 months (-1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; ...; 8 = payment delay for eight months; 9 = payment delay for nine months and above)\n",
    "* BILL_AMT1 to BILL_AMT6: Amount of bill statement for the past 6 months\n",
    "* PAY_AMT1 to PAY_AMT6: Amount of previous monthly payments in New Taiwan Dollar for the past 6 months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Spark and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Find\" PySpark and start a Spark session\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe unneccessary packages - TEST\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore data\n",
    "\n",
    "The data is provided in an Excel file and read into a dataframe. Before reading the data, this file was converted to a csv file and the first line with generic column names was deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 30000\n",
      "Number of columns: 25\n",
      "Column names: ['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'DEFAULT']\n"
     ]
    }
   ],
   "source": [
    "# Read csv file\n",
    "data = spark.read.csv(\"data/default of credit card clients.csv\", sep = \";\", header = True, inferSchema = True)\n",
    "\n",
    "# Give the label column a shorter name\n",
    "data = data.withColumnRenamed(\"default payment next month\", \"DEFAULT\")\n",
    "\n",
    "print(\"Number of observations:\", data.count())\n",
    "print(\"Number of columns:\", len(data.schema.names))\n",
    "print(\"Column names:\", data.schema.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+---------+--------+---+-----+-----+---------+---------+-------+\n",
      "| ID|LIMIT_BAL|SEX|EDUCATION|MARRIAGE|AGE|PAY_0|PAY_0|BILL_AMT1|BILL_AMT2|DEFAULT|\n",
      "+---+---------+---+---------+--------+---+-----+-----+---------+---------+-------+\n",
      "|  1|    20000|  2|        2|       1| 24|    2|    2|     3913|     3102|      1|\n",
      "|  2|   120000|  2|        2|       2| 26|   -1|   -1|     2682|     1725|      1|\n",
      "|  3|    90000|  2|        2|       2| 34|    0|    0|    29239|    14027|      0|\n",
      "|  4|    50000|  2|        2|       1| 37|    0|    0|    46990|    48233|      0|\n",
      "|  5|    50000|  1|        2|       1| 57|   -1|   -1|     8617|     5670|      0|\n",
      "+---+---------+---+---------+--------+---+-----+-----+---------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.select(\"ID\", \"LIMIT_BAL\", \"SEX\", \"EDUCATION\", \"MARRIAGE\", \"AGE\", \"PAY_0\", \"PAY_0\", \n",
    "                  \"BILL_AMT1\", \"BILL_AMT2\", \"DEFAULT\").show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is imbalanced: Only 22% of all customers defaulted, i.e. have a label of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default == 1: 6636\n",
      "Default == 0: 23364\n"
     ]
    }
   ],
   "source": [
    "print(\"Default == 1:\", data.filter(data.DEFAULT == 1).count())\n",
    "print(\"Default == 0:\", data.filter(data.DEFAULT == 0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|DEFAULT|count(DEFAULT)|\n",
      "+-------+--------------+\n",
      "|      1|          6636|\n",
      "|      0|         23364|\n",
      "+-------+--------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Same query with Spark SQL: \n",
    "data.createOrReplaceTempView(\"view1\")\n",
    "print(spark.sql(\"SELECT DEFAULT, count(DEFAULT) from view1 group by DEFAULT\").show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation pipeline\n",
    "\n",
    "The data is first split into a training and a test sample. The pipeline essentially just converts all categorical features as such and normalizes all numerical features. \n",
    "\n",
    "The features PAY_0 to PAY_6 are not strictly numerical and, for a proper analysis, should probably be factorized as well. As this notebook is just for practicing, that doesn't really matter though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID column\n",
    "data = data.select(data.schema.names[1:])\n",
    "\n",
    "# Split data into training and test sample\n",
    "splits = data.randomSplit([0.75, 0.25])\n",
    "data_train = splits[0]\n",
    "data_test = splits[1]\n",
    "\n",
    "# Get and convert categorical features (SEX, EDUCATION, MARRIAGE)\n",
    "categorical_features = data.schema.names[1:4]\n",
    "catVect = VectorAssembler(inputCols = categorical_features, outputCol = \"catFeatures\")\n",
    "catIdx = VectorIndexer(inputCol = catVect.getOutputCol(), outputCol = \"idxCatFeatures\")\n",
    "\n",
    "# Get and normalize numerical features\n",
    "numerical_features = data.schema.names[0:1] + data.schema.names[4:]\n",
    "numVect = VectorAssembler(inputCols = numerical_features, outputCol = \"numFeatures\")\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol = \"normFeatures\")\n",
    "\n",
    "# Define pipeline \n",
    "featVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], outputCol = \"features\")\n",
    "pipeline = Pipeline(stages = [catVect, catIdx, numVect, minMax, featVect])\n",
    "pipeline_object = pipeline.fit(data_train)\n",
    "\n",
    "# Run training and test data through the pipeline\n",
    "data_train = pipeline_object.transform(data_train).select(\"features\", col(\"DEFAULT\").alias(\"label\"))\n",
    "data_test = pipeline_object.transform(data_test).select(\"features\", col(\"DEFAULT\").alias(\"label\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.0,1.0,1.0,0.0,...|    1|\n",
      "|(24,[1,2,4,5,6,7,...|    1|\n",
      "|[0.0,1.0,1.0,0.0,...|    0|\n",
      "|[0.0,1.0,1.0,0.0,...|    0|\n",
      "|[0.0,1.0,1.0,0.0,...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "Number of observations in training / test data: 22668 / 7332\n"
     ]
    }
   ],
   "source": [
    "print(data_train.show(5))\n",
    "print(\"Number of observations in training / test data:\", data_train.count(), \"/\", data_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol = \"label\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
    "precision = MulticlassClassificationEvaluator(\n",
    "    labelCol = \"label\", predictionCol = \"prediction\", metricName = \"weightedPrecision\")\n",
    "recall = MulticlassClassificationEvaluator(\n",
    "    labelCol = \"label\", predictionCol = \"prediction\", metricName = \"weightedRecall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "https://spark.apache.org/docs/2.2.0/api/python/pyspark.ml.html#pyspark.ml.classification.LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9857\n",
      "Weighted precision: 0.9859\n",
      " Weighted recall: 0.9857\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(labelCol = \"label\", featuresCol = \"features\", maxIter = 20, regParam = 0.2)\n",
    "model = logit.fit(data_train)\n",
    "predictions_df = model.transform(data_test)\n",
    "\n",
    "print(\"Accuracy: {:.4}\".format(accuracy.evaluate(predictions_df)))\n",
    "print(\"Weighted precision: {:.4}\".format(precision.evaluate(predictions_df)))\n",
    "print(\" Weighted recall: {:.4}\".format(recall.evaluate(predictions_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree\n",
    "\n",
    "https://spark.apache.org/docs/2.2.0/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Weighted precision: 1.0\n",
      "Weighted recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(labelCol = \"label\", featuresCol = \"features\", maxDepth = 4, maxBins = 32, \n",
    "                              minInstancesPerNode = 1, minInfoGain = 0.0, impurity = \"gini\", seed = 123)\n",
    "model = tree.fit(data_train)\n",
    "predictions_df = model.transform(data_test)\n",
    "\n",
    "print(\"Accuracy: {:.4}\".format(accuracy.evaluate(predictions_df)))\n",
    "print(\"Weighted precision: {:.4}\".format(precision.evaluate(predictions_df)))\n",
    "print(\"Weighted recall: {:.4}\".format(recall.evaluate(predictions_df)))\n",
    "# always perfect scores - something doesn't seem right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "\n",
    "https://spark.apache.org/docs/2.2.0/api/python/pyspark.ml.html#pyspark.ml.classification.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9208\n",
      "Weighted precision: 0.9281\n",
      "Weighted recall: 0.9208\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol = \"label\", featuresCol = \"features\", maxDepth = 4, maxBins = 32, \n",
    "                            minInstancesPerNode = 1, minInfoGain=0.0, impurity = \"gini\", numTrees = 10, seed = 123) \n",
    "model = rf.fit(data_train)\n",
    "predictions_df = model.transform(data_test)\n",
    "\n",
    "print(\"Accuracy: {:.4}\".format(accuracy.evaluate(predictions_df)))\n",
    "print(\"Weighted precision: {:.4}\".format(precision.evaluate(predictions_df)))\n",
    "print(\"Weighted recall: {:.4}\".format(recall.evaluate(predictions_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating (unweighted) metrics manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positives: 1043\n",
      "false positives: 0\n",
      "true negatives: 5708\n",
      "false negatives: 581\n",
      "Accuracy: 0.9208\n",
      "Precision: 1.0\n",
      "Recall: 0.6422\n"
     ]
    }
   ],
   "source": [
    "tp = int(predictions_df.filter(\"prediction == 1.0 AND label == 1\").count())\n",
    "fp = int(predictions_df.filter(\"prediction == 1.0 AND label == 0\").count())\n",
    "tn = int(predictions_df.filter(\"prediction == 0.0 AND label == 0\").count())\n",
    "fn = int(predictions_df.filter(\"prediction == 0.0 AND label == 1\").count())\n",
    "\n",
    "print(\"true positives:\", tp)\n",
    "print(\"false positives:\", fp)\n",
    "print(\"true negatives:\", tn)\n",
    "print(\"false negatives:\", fn)\n",
    "\n",
    "print(\"Accuracy: {:.4}\".format((tp+tn)/(tp+fp+tn+fn)))\n",
    "print(\"Precision: {:.4}\".format((tp)/(tp+fp)))\n",
    "print(\"Recall: {:.4}\".format((tp)/(tp+fn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
